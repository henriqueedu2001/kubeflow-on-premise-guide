{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b95dfb",
   "metadata": {},
   "source": [
    "# Verificação de GPUs\n",
    "Esse notebook serve para verificar se você tem GPUs visíveis no ambiente em que ele for rodado. Por exemplo, se você o executar em sua máquina local, ele exibirá as GPUs da sua máquina, caso existam, e rodará um teste de desempenho (benchmark), visando verificar que, de fato, elas estão acessíveis e funcionais.\n",
    "\n",
    "O benchmark nada mais é que a execução de multiplicação de matrizes quadradas de tamanho n = 8192, tanto na CPU quanto nas GPUs. Mede-se o tempo de execução para a CPU e as GPUs e compara-se no final. Se as GPUs fizerem o cálculo em menor tempo que as GPUs, então o teste foi bem sucedido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def check_gpus():\n",
    "    \"\"\"Prints the available GPUs of your computational environment.\n",
    "\n",
    "    Example::\n",
    "        >>> check_gpus()\n",
    "        '''\n",
    "        CUDA Available\n",
    "        GPUs found: 1\n",
    "        #1 GPU:\n",
    "            - Name: NVIDIA GeForce RTX 4050 Laptop GPU\n",
    "            - Capability: (8, 9)\n",
    "            - Memory (GB): 5.64\n",
    "        ...\n",
    "        '''\n",
    "    \"\"\"\n",
    "    # checks if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        print('CUDA Available')\n",
    "    else:\n",
    "        print('CUDA isn\\'t available')\n",
    "        return\n",
    "\n",
    "    # prints the GPUs\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f'GPUs found: {gpu_count}')\n",
    "    for i in range(gpu_count):\n",
    "        print(f'#{i + 1} GPU:')\n",
    "        print(f'\\t-Name: {torch.cuda.get_device_name(i)}')\n",
    "        print(f'\\t-Capability: {torch.cuda.get_device_capability(i)}')\n",
    "        print(f'\\t-Memory (GB): {round(torch.cuda.get_device_properties(i).total_memory / 1024**3, 2)}')\n",
    "        print()\n",
    "\n",
    "\n",
    "def benchmark(n: str = 8192):\n",
    "    \"\"\"Benchmarks the performance of the GPUs against the baseline of the CPU in multiplication of random\n",
    "    matrices n x n.\n",
    "\n",
    "    Args:\n",
    "        n (str, optional): The size of the matrices. Defaults to 8192.\n",
    "    \n",
    "    Example:\n",
    "        >>> benchmark()\n",
    "        '''\n",
    "        Benchmark: multiplication of random matrices 8192 x 8192\n",
    "        CPU time: 2.2724 s\n",
    "        GPU time: 0.1996 s\n",
    "        Speedup GPU vs CPU: 11.39x\n",
    "        Success: True\n",
    "        '''\n",
    "    \"\"\"\n",
    "    print(f'Benchmark: multiplication of random matrices {n} x {n}')\n",
    "    a_cpu = np.random.rand(n, n).astype(np.float32)\n",
    "    b_cpu = np.random.rand(n, n).astype(np.float32)\n",
    "\n",
    "    # medição do tempo da CPU\n",
    "    start_cpu = time.perf_counter()\n",
    "    c_cpu = a_cpu @ b_cpu\n",
    "    end_cpu = time.perf_counter()\n",
    "    cpu_time = end_cpu - start_cpu\n",
    "    print(f'CPU time: {cpu_time:.4f} s')\n",
    "        \n",
    "    assert torch.cuda.is_available(), 'CUDA não disponível'\n",
    "    device = torch.device('cuda')\n",
    "    a_gpu = torch.randn(n, n, device=device)\n",
    "    b_gpu = torch.randn(n, n, device=device)\n",
    "\n",
    "    # aquecimento\n",
    "    for _ in range(3):\n",
    "        _ = a_gpu @ b_gpu\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # medição do tempo da GPU\n",
    "    start_gpu = time.perf_counter()\n",
    "    c_gpu = a_gpu @ b_gpu\n",
    "    torch.cuda.synchronize()\n",
    "    end_gpu = time.perf_counter()\n",
    "    gpu_time = end_gpu - start_gpu\n",
    "    print(f'GPU time: {gpu_time:.4f} s')\n",
    "    \n",
    "    print(f'Speedup GPU vs CPU: {cpu_time / gpu_time:.2f}x')\n",
    "    print(f'Success: {gpu_time < cpu_time}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65b74bb-cd40-4b8f-ac7e-74a8b0cd16f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available\n",
      "GPUs found: 1\n",
      "#1 GPU:\n",
      "\t-Name: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "\t-Capability: (8, 9)\n",
      "\t-Memory (GB): 5.64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee65843-b466-4fe1-b55e-3aa1ee7d776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark: multiplication of random matrices 8192 x 8192\n",
      "CPU time: 2.2724 s\n",
      "GPU time: 0.1996 s\n",
      "Speedup GPU vs CPU: 11.39x\n",
      "Success: True\n"
     ]
    }
   ],
   "source": [
    "benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
